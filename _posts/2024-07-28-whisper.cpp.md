---
layout: post
title:  "Playing with Whisper"
categories: ml
published: false
last_edit: 2025-07-10
---

Whisper is an OpenSource transcription library(MIT)and model released by OpenAI which transcribes audio. As an integral part of using voice as input for programs I wanted to explore the many different options of running it locally.

For all of these exploration I will also run a rough test using a sample audio file from audible.  The first book of the Bobiverse: We are Legion by Dennis E. Taylor
```bash
curl --output bobiverse-sample.mp3 \
'https://samples.audible.com/bk/adbl/027284/bk_adbl_027284_sample.mp3'
ffmpeg -i bobiverse-sample.mp3 -ar 16000 -ac 1 -c:a pcm_s16le bobiverse-sample.wav
```

This test is not exactly scientific but for each method of running the model I ran the test a few times until the speed stabilized and provided a single result.  All tests are using just about the same model though there may be some slight changes to the weights when they're ported to the different formats.  In the end I will compare the transcription results to see if there was any meaningful differences in the transcriptions.

# OpenAI Whisper
[{% include github-icon.html %} openai/whisper](https://github.com/openai/whisper)

## Setup
```zsh
mkdir -p openai-whisper && cd openai-whisper
uv venv --python 3.11.13
source .venv/bin/activate
uv pip install openai-whisper
```

## Transcription performance
```bash
time whisper --model base.en --model_dir . ../bobiverse-sample.wav  --output_format json > /dev/null 2>&1
55.34s user 18.71s system 197% cpu 37.422 total

cat bobiverse-sample.json | jq ".segments.[].text"
```

# Whisper.cpp
[{% include github-icon.html %} ggerganov/whisper.cpp](https://github.com/ggerganov/whisper.cpp)

This is an especially compelling way to run whisper locally as it has been optimized for Apple Silcon.

## Setup
Building the model for coreml
```bash
git clone https://github.com/ggerganov/whisper.cpp.git
cd whisper.cpp

uv venv --python 3.11
uv pip install ane_transformers openai-whisper coremltools
source .venv/bin/activate

cmake -B build -DWHISPER_COREML=1 -DWHISPER_SDL2=ON
cmake --build build -j --config Release

sh ./models/download-ggml-model.sh base.en
./models/generate-coreml-model.sh base.en
```
Note that python 3.11 is not the latest python as of development but coremltools does not appear to work on later versions of python.

An exploration of whisper.cpp cli tools
```bash
# capture a wav using ffmpeg and then transcribe
ffmpeg -f avfoundation -i ":0" -t 10 -ar 16000 -ac 1 -c:a pcm_s16le capture.wav
./build/bin/whisper-cli -m models/ggml-base.en.bin -f capture.wav --print-colors

# stream audio for a microphone and transcribe
./build/bin/whisper-stream -m ./models/ggml-base.en.bin -t 8 --step 500 --length 5000
```

## Transcription performance
```bash
time ./build/bin/whisper-cli -m models/ggml-base.en.bin -f ../bobiverse-sample.wav -of bobiverse-sample -otxt > /dev/null 2>&1
2.55s user 0.25s system 57% cpu 4.899 total

cat bobiverse-sample.json | jq ".transcription.[].text"
```

```jq
```

## Faster Whisper
[{% include github-icon.html %} SYSTRAN/faster-whisper](https://github.com/SYSTRAN/faster-whisper)

## Setup
```zsh
mkdir -p faster-whisper && cd faster-whisper
uv venv --python 3.11.13
source .venv/bin/activate
uv pip install faster-whisper
```


## Performance Test

```python
from faster_whisper import WhisperModel

# Run on CPU with INT8
model = WhisperModel("base.en", device="cpu", compute_type="int8")

segments, info = model.transcribe("../bobiverse-sample.wav", beam_size=5)

print("Detected language '%s' with probability %f" % (info.language, info.language_probability))

for segment in segments:
    print("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))
```

To get the performance I executed the script above.  Note that with mac silicon I could not take advantage of the gpu or neural processing units.
```bash
time python transcribe-bobiverse.py > bobiverse-sample.txt
57.81s user 8.97s system 399% cpu 16.714 total
```


# Overall Comparisons

## Comparing OpenAI and Whisper.cpp
```bash
diff --ignore-space-change \
<( cd whisper.cpp; cat bobiverse-sample.json | jq -r ".transcription.[].text") \
<(cd openai-whisper; cat bobiverse-sample.json | jq -r ".segments.[].text")
```

Mostly minor differences in how the blocks were split.  A few punctuation changes

Punctuation Example
{:.code-title}
```diff
<  Well, what the hell?
---
>  Well, what the hell.
```

Word Difference Example
{:.code-title}
```diff
<  That appeared there was money in cryonics.
---
>  It appeared there was money in cryonics.
```
